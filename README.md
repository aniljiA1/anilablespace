# ğŸ“š Product Data Explorer â€” Full-Stack Assignment

A production-minded **Product Exploration Platform** that allows users to navigate from **high-level navigation headings â†’ categories â†’ products â†’ detailed product pages**, powered by **on-demand live scraping** from **World of Books**.

This project demonstrates **scalable full-stack engineering**, **ethical scraping**, **queue-based architecture**, and **modern frontend UX**.

---

## ğŸ”— Live Links



---

## ğŸ§± Architecture Overview

Next.js (App Router)
â†“ React Query (SWR-style)
NestJS API (REST)
â†“ Queue (BullMQ + Redis)
Crawlee + Playwright
â†“
WorldOfBooks.com

markdown
Copy code

- **Non-blocking scraping** via background jobs
- **Database-backed caching** to prevent repeated scrapes
- **Idempotent scrape jobs** with deduplication
- **Client + server navigation history persistence**

---

## ğŸ–¥ï¸ Frontend

### Tech Stack
- Next.js (App Router)
- React + TypeScript
- Tailwind CSS
- React Query
- Axios

### Core Pages
- **Landing / Home** â€” navigation headings
- **Category Drilldown**
- **Product Grid** (pagination + limit)
- **Product Detail Page**
  - Description
  - Ratings & reviews
  - Related products
  - Metadata (ISBN, publisher, etc.)
- **About / Contact / README**

### UX & Accessibility
- Responsive (mobile + desktop)
- Skeleton loaders & smooth transitions
- Semantic HTML
- Keyboard navigation
- WCAG AA color contrast
- `alt` text for all images

---

## ğŸ§  Backend

### Tech Stack
- NestJS (Node.js + TypeScript)
- PostgreSQL (relational scraping data)
- Prisma ORM
- BullMQ + Redis (job queue)
- Crawlee + Playwright (scraping)
- class-validator (DTO validation)

### Why PostgreSQL?
- Strong relational modeling (navigation â†’ category â†’ product)
- Indexing for `source_id`, `source_url`
- JSON support for flexible metadata
- Production-ready & scalable

---

## ğŸ•·ï¸ Scraping (World of Books)

- **Target**: https://www.worldofbooks.com/
- **Framework**: Crawlee + Playwright
- **Scraped Data**:
  - Navigation headings
  - Categories & subcategories
  - Product cards (title, author, price, image)
  - Product details
  - Reviews & ratings (if available)
  - Related products
  - ISBN, publisher, publication date

### Ethical Scraping
âœ” Respects `robots.txt`  
âœ” Rate limiting + delays  
âœ” Exponential backoff  
âœ” Cached results with expiry  
âœ” Manual re-fetch allowed  

---

## ğŸ—„ï¸ Database Schema (Core Entities)

- `navigation`
- `category`
- `product`
- `product_detail`
- `review`
- `scrape_job`
- `view_history`

Indexes:
- `source_id`
- `source_url`
- `last_scraped_at`

---

## ğŸ”Œ API Endpoints

```http
GET  /navigation
GET  /categories/:slug
GET  /products?category=&page=&limit=
GET  /products/:id
POST /scrape/product
POST /history
Scrapes are triggered on-demand

Requests never block on scraping

Cached data served immediately if valid

ğŸš€ Local Setup
Prerequisites
Node.js 18+

PostgreSQL

Redis

1ï¸âƒ£ Clone Repository
bash
Copy code
git clone https://github.com/your-username/product-data-explorer.git
cd product-data-explorer
2ï¸âƒ£ Frontend Setup
bash
Copy code
cd frontend
npm install
npm run dev
Create .env.local:


3ï¸âƒ£ Backend Setup
bash
Copy code
cd backend
npm install
npx prisma migrate dev
npm run start:dev
Create .env:

env
Copy code
DATABASE_URL=postgresql://user:password@localhost:5432/products
REDIS_URL=redis://localhost:6379
4ï¸âƒ£ Scraper Worker
bash
Copy code
cd scraper
npm install
npm run start
ğŸ§ª Engineering Highlights
Queue-based scraping (BullMQ)

Idempotent jobs

Safe concurrency limits

Request deduplication

Graceful error handling

Centralized logging

DTO validation

CORS + rate limiting

ğŸ” Security & Reliability
Environment variables secured

No secrets committed

Input sanitization

Minimal API rate limiting

Retry + backoff for external calls

ğŸ“ˆ Observability
Console + file logging

Job status tracking

Error capture per scrape job

ğŸ§© Future Improvements
Auth + user accounts

Full-text search

Scheduled re-scrapes

Admin dashboard

Elasticsearch

CDN image proxy

ğŸ“ Notes
This project was built specifically for a production-grade full-stack assessment, emphasizing clean architecture, ethical scraping, and scalability over shortcuts.

ğŸ‘¤ Author
Anil Kumar
